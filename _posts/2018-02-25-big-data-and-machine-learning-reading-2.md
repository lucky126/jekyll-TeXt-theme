---
layout: post
title: 《白话大数据与机器学习》读书笔记2
key: 20180225
tags:
  - 大数据
  - 机器学习
  - 读书笔记
  - 信息
lang: zh-Hans
---

# 《白话大数据与机器学习》读书笔记2

## 信息论

### 信息

信息是被消除的不确定性
<!--more-->
### 信息量

$$I=\log_2m$$

*对数*：如果$a$的$x$次方等于$N$（a>0，且a不等于1），那么数$x$叫做以$a$为底$N$的对数（logarithm），记作$x=\log_aN$。其中，a叫做对数的底数，N叫做真数。

事件出现的概率越小，信息量越大，即信息量的多少是与事件发生频率程度大小（即概率大小）恰好相反的。公式如下：

$$H(X_i)=-\log_2P$$

### 香农公式

$$C=B\cdot \log_2\left(1+\frac{S}{N}\right)$$

单位 bps

其中：

* B 是码元速率的极限值 （B=2H，H 为信道带宽，单位为 Baud）
* S 是信号功率（瓦）
* N 是噪声功率（瓦）

### 熵

#### 热力熵

#### 信息熵

$$H(x)=-\sum_{i=1}^np(x_i)\log_2P(x_1)，i=1,2,{\cdots},n$$

其中，$x$可以当成一个向量，就是若干个$x_i$产生的概率乘以该可能性的信息量，然后各项做加和。


> 信息越确定，越单一，信息熵越小；
>
> 信息越不确定，越混乱，信息熵越大。

## 多维向量空间

### 向量（Vector）

几何向量也称欧几里得向量，通常简称向量、矢量，是指具有具体大小和方向的几何对象表示。

>向量实例：（'北京','电风扇'）
>
>向量定义：（地区，产品类别）

### 矩阵（Matrix）

$$A=\begin{bmatrix}
{a_{11}}&{a_{12}}&{\cdots}&{a_{1n}}\\
{a_{21}}&{a_{22}}&{\cdots}&{a_{2n}}\\
{\vdots}&{\vdots}&{\ddots}&{\vdots}\\
{a_{m1}}&{a_{m2}}&{\cdots}&{a_{mn}}\\
\end{bmatrix}$$

A是一个$m\times n$矩阵。在本例中，每个矩阵的元素$a_{mn}$都是一个数字。

#### 矩阵加法，减法

同型矩阵可以做加减法，对应元素做加减法即可，结果矩阵维度不变。

#### 矩阵的数乘

矩阵数乘就是矩阵每个元素都乘以这个数乘倍数。

#### 矩阵的转置

矩阵转置记做$A^T$，行变列，列变行即可。

#### 矩阵的内积

$$A_{mn}\cdot B_{nk} = C_{mk}$$

## 回归

回归分析的英文是Regression，单词原型的regress大概的意思是"回退，退化，倒退"。回归借用了"倒退，倒推"的含义。简单说就是"由果索因"的过程。

### 拟合

把平面上一系列的点用一条光滑的曲线连接起来的过程叫做拟合。


### 过拟合

危害：
1. 描述复杂
2. 失去泛化能力，所谓泛化能力就是通过机器学习得到的模型对未知数据的预测能力，即应用于其他非训练样本的向量时的分类能力。

造成的原因最常见的两种：

1. 训练样本太少
2. 力求“完美”

### 欠拟合

原因：
1. 参数太少
2. 拟合不当
